{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises (OOP with Python)\n",
    "\n",
    "## Exercise 1: Creating class, attributes, methods with Online Shopping Cart\n",
    "Create a class called _Shopping_\n",
    "1. Each _Shopping_ must contain the following attributes:\n",
    "   - __name__ which indicates the name of the user example: Shopping(\"Rita\")\n",
    "   - __cart__ which indicates the list of goods selected..\n",
    "   - __balance__ which indicates the total cost of the goods selected. Default value is 0.0.\n",
    "   <br>\n",
    "2. Each _Shopping_ must contain the following methods:\n",
    "   - __select__ which takes in 2 arguments: _name_ indicating item selected and _price_ (default value 0.0) indicating price of the good selected. It should add the price to the __balance__ attribute and the item name to the list attribute __cart__ . Finally it should return the new __cart__ attribute. \n",
    "   - __check_balance__ which returns a print statement as follows: \"Your current balance is {self.balance} Eur\"\n",
    "   - __remove_item__ which takes 2 attributes: _name_ indicating item and _price_ (default value 0.0) indicating price of the item. It should subtract the price from the __balance__ attribute and delete the item name from the list attribute __cart__ . Finally it should return the new __cart__ attribute.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Multiple Inheritance and mro with Mendel's Dominant and Recessive Traits Theory\n",
    "Create two classes __Dominant__ and __Recessive__ having attributes:\n",
    "1. The dominant class has following attributes: __seed_shape__ (default='round'), __pod_color__ (default='green'), __flower_color__(default='purple')\n",
    "2. The recessive class has following attributes: __seed_shape__ (default='wrinkled'), __pod_color__ (default='yellow'), __flower_color__(default='white')\n",
    "3. Create subclass __Pea__ which inherits from the above two classes, having same attributes but donot spcify them. Let Python's mro assign them to the \"dominant\" traits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Inheritance, name wrangling, class methods with Online Video Calling App\n",
    "Create a class __VideoApp__\n",
    "1. The _VideoApp_ must contain the following class attributes:\n",
    "   - __participants_online__ which contains the number of active callers default to 0\n",
    "   - _action_ containing a list of 2 strings: \"speaking\", \"silent\"\n",
    "2. The_VideoApp_ must contain the class method:\n",
    "   - __show_participants_online__ which returns the following message: \"{cls.participants_online} are attending meeting.\"\n",
    "3.  The _VideoApp_ must contain the following attributes:\n",
    "   - __user_name__ which assigns name of the caller\n",
    "   - _company_ which indicates the company represented by the caller \n",
    "   \n",
    "4.  The _VideoApp_ must contain the following methods: \n",
    "   - __go_online__ which increases the attribute _participants_online by 1\n",
    "   - __go_offline__ which subtracts 1 from the attribute _participants_online and returns the new _participants_online\n",
    "   - _status_ which takes argument _action_ and checks if the action argument matches the string in the _action_ class attribute, otherwise throws ValueError: \"The user must either be \"speaking\" or \"silent\"\". It also returns the message: \"{self.user_name} is _action_\"\n",
    "\n",
    "Create another class __Message__\n",
    "1. It has following attributes: \n",
    "   - __user_name__\n",
    "   - _message_\n",
    "2. It has one method:\n",
    "   - _status_ which returns: \"{self.user_name} sent the message: {self.message}\"\n",
    "\n",
    "Create another class __ChatApp__ which inherits from both parent classes in the following order: __VideoApp__ and __Message__ \n",
    "1. Each _ChatApp_ takes same attributes as base classes\n",
    "2. It has a method _status_ which basically name wrangles the method _status_ from _Message_ class. \n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: OOP with application to scVI\n",
    "This exercise will help you to identify how OOP has been used in scvi codes to build Deep Generative modeling for Single Cell Transcriptonomics. You can find more about the basic usage from __[scVI_Basic_Usage](https://github.com/YosefLab/scVI/blob/master/tests/notebooks/basic_tutorial.ipynb)__ \n",
    "<br> In the following exercise we will work with some extracts of codes from scvi notebooks, and try to answer the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.1\n",
    "The following is an excerpt from the __Trainer__ class under inference subfolder. The whole file is available under: __[scVI_trainer.py](https://github.com/YosefLab/scVI/blob/master/scvi/inference/trainer.py)__ :\n",
    "<br> \\[N.B. Do not worry if you still donot understand everything about the code at this point as we will talk about inference and variational autoencoders later on in this course. Also some parts have been omitted for simplicity\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    r\"\"\"The abstract Trainer class for training a PyTorch model and monitoring its statistics. It should be\n",
    "    inherited at least with a .loss() function to be optimized in the training loop.\n",
    "    Args:\n",
    "        :model: A model instance from class ``VAE``, ``VAEC``, ``SCANVI``\n",
    "        :gene_dataset: A gene_dataset instance like ``CortexDataset()``\n",
    "        :use_cuda: Default: ``True``.\n",
    "        :metrics_to_monitor: A list of the metrics to monitor. If not specified, will use the\n",
    "            ``default_metrics_to_monitor`` as specified in each . Default: ``None``.\n",
    "        :benchmark: if True, prevents statistics computation in the training. Default: ``False``.\n",
    "        :verbose: If statistics should be displayed along training. Default: ``None``.\n",
    "        :frequency: The frequency at which to keep track of statistics. Default: ``None``.\n",
    "        :early_stopping_metric: The statistics on which to perform early stopping. Default: ``None``.\n",
    "        :save_best_state_metric:  The statistics on which we keep the network weights achieving the best store, and\n",
    "            restore them at the end of training. Default: ``None``.\n",
    "        :on: The data_loader name reference for the ``early_stopping_metric`` and ``save_best_state_metric``, that\n",
    "            should be specified if any of them is. Default: ``None``.\n",
    "    \"\"\"\n",
    "    default_metrics_to_monitor = []\n",
    "\n",
    "    def __init__(self, model, gene_dataset, use_cuda=True, metrics_to_monitor=None, benchmark=False,\n",
    "                 verbose=False, frequency=None, weight_decay=1e-6, early_stopping_kwargs=dict(),\n",
    "                 data_loader_kwargs=dict()):\n",
    "\n",
    "        self.model = model\n",
    "        self.gene_dataset = gene_dataset\n",
    "\n",
    "        self.data_loader_kwargs = {\n",
    "            \"batch_size\": 128,\n",
    "            \"pin_memory\": use_cuda\n",
    "        }\n",
    "        self.data_loader_kwargs.update(data_loader_kwargs)\n",
    "\n",
    "        self.weight_decay = weight_decay\n",
    "        self.benchmark = benchmark\n",
    "        self.epoch = -1  # epoch = self.epoch + 1 in compute metrics\n",
    "        self.training_time = 0\n",
    "        self.early_stopping = EarlyStopping(**early_stopping_kwargs)\n",
    "    \n",
    "    def __getattr__(self, name):\n",
    "        if '_posteriors' in self.__dict__:\n",
    "            _posteriors = self.__dict__['_posteriors']\n",
    "            if name.strip('_') in _posteriors:\n",
    "                return _posteriors[name.strip('_')]\n",
    "        return object.__getattribute__(self, name)\n",
    "\n",
    "    def __delattr__(self, name):\n",
    "        if name.strip('_') in self._posteriors:\n",
    "            del self._posteriors[name.strip('_')]\n",
    "        else:\n",
    "            object.__delattr__(self, name)\n",
    "            \n",
    "\n",
    "    def register_posterior(self, name, value):\n",
    "        name = name.strip('_')\n",
    "        self._posteriors[name] = value\n",
    "\n",
    "    def corrupt_posteriors(self, rate=0.1, corruption=\"uniform\", update_corruption=True):\n",
    "        if not hasattr(self.gene_dataset, 'corrupted') and update_corruption:\n",
    "            self.gene_dataset.corrupt(rate=rate, corruption=corruption)\n",
    "        for name, posterior in self._posteriors.items():\n",
    "            self.register_posterior(name, posterior.corrupted())\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your previous knowledge of OOP and looking at the code above, answer the following questions:\n",
    "1. What are the arguments with default values stated in the __Trainer__ class i.e. name the arguments which are not necessary to include while instantiating the __Trainer__ class?\n",
    "2. Can you name at least 2 model names the user can use as arguments while instantiating the class __Trainer__? e.g: train_object=Trainer(model=?,gene_dataset,...)\n",
    "3. Can you name two arguments where you can use variable length of the arguments while instantiating the __Trainer__ class?\n",
    "4. List all the methods that you can see under __Trainer__ class. Which of these are Dunder methods?\n",
    "5. We want to be able to call the __corrupt\\_posteriors__ method as an attribute of the __Trainer__ class. Modify the above code to enable this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercise 4.2\n",
    "The following is an excerpt from the __Inference.py__ file under inference subfolder. The whole file is available under: __[scVI_inference.py](https://github.com/YosefLab/scVI/blob/master/scvi/inference/inference.py)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsupervisedTrainer(Trainer):\n",
    "    r\"\"\"The VariationalInference class for the unsupervised training of an autoencoder.\n",
    "    Args:\n",
    "        :model: A model instance from class ``VAE``, ``VAEC``, ``SCANVI``\n",
    "        :gene_dataset: A gene_dataset instance like ``CortexDataset()``\n",
    "        :train_size: The train size, either a float between 0 and 1 or and integer for the number of training samples\n",
    "         to use Default: ``0.8``.\n",
    "        :\\*\\*kwargs: Other keywords arguments from the general Trainer class.\n",
    "    Examples:\n",
    "        >>> gene_dataset = CortexDataset()\n",
    "        >>> vae = VAE(gene_dataset.nb_genes, n_batch=gene_dataset.n_batches * False,\n",
    "        ... n_labels=gene_dataset.n_labels)\n",
    "        >>> infer = VariationalInference(gene_dataset, vae, train_size=0.5)\n",
    "        >>> infer.train(n_epochs=20, lr=1e-3)\n",
    "    \"\"\"\n",
    "    default_metrics_to_monitor = ['ll']\n",
    "\n",
    "    def __init__(self, model, gene_dataset, train_size=0.8, test_size=None, kl=None, **kwargs):\n",
    "        super().__init__(model, gene_dataset, **kwargs)\n",
    "        self.kl = kl\n",
    "        if type(self) is UnsupervisedTrainer:\n",
    "            self.train_set, self.test_set = self.train_test(model, gene_dataset, train_size, test_size)\n",
    "            self.train_set.to_monitor = ['ll']\n",
    "            self.test_set.to_monitor = ['ll']\n",
    "\n",
    "    @property\n",
    "    def posteriors_loop(self):\n",
    "        return ['train_set']\n",
    "\n",
    "\n",
    "class AdapterTrainer(UnsupervisedTrainer):\n",
    "    def __init__(self, model, gene_dataset, posterior_test, frequency=5):\n",
    "        super().__init__(model, gene_dataset, frequency=frequency)\n",
    "        self.test_set = posterior_test\n",
    "        self.test_set.to_monitor = ['ll']\n",
    "        self.params = list(self.model.z_encoder.parameters()) + list(self.model.l_encoder.parameters())\n",
    "\n",
    "    @property\n",
    "    def posteriors_loop(self):\n",
    "        return ['test_set']\n",
    "\n",
    "    def train(self, n_path=10, n_epochs=50, **kwargs):\n",
    "        for i in range(n_path):\n",
    "            # Re-initialize to create new path\n",
    "            self.model.z_encoder.load_state_dict(self.z_encoder_state)\n",
    "            self.model.l_encoder.load_state_dict(self.l_encoder_state)\n",
    "            super().train(n_epochs, params=self.params, **kwargs)\n",
    "\n",
    "        return min(self.history[\"ll_test_set\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions:\n",
    "1. Which class does __UnsupervisedTrainer__ inherit from?\n",
    "2. If we print the AdapterTrainer.\\_\\_mro\\_\\_, what order of inheritance would you see?\n",
    "3. Look at the __posteriors\\_loop__ method for the class AdapterTrainer. Modify the code such that now we donot want this to be the attribute of the class, but rather as a method which takes in argument _set_ and returns this value and default it to 'test_set'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
